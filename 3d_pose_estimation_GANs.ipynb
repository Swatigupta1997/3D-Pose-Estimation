{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3d_pose_estimation_GANs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X38L6tanrnrB"
      },
      "source": [
        "# 3-D Pose Estimation using GANs\n",
        "\n",
        "This notebook is the python implementation of 3-D pose estimation from 2-D joint poses inspired by the research paper [Unsupervised adversarial learning of 3d human pose from 2d joint locations](https://arxiv.org/pdf/1803.08244.pdf) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwhGR_CWTYW_"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib as mpl\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torchsummary import summary\n",
        "import random\n",
        "import json\n",
        "import glob \n",
        "from mpl_toolkits import mplot3d\n",
        "import datetime\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWdEYmRdy4wB",
        "outputId": "b8d194f3-555d-4938-eaa3-5b4b54f49eb3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mU4g6SB-eFM8",
        "outputId": "fe762ccb-6299-45fc-dc22-ee90b8576853"
      },
      "source": [
        "# Set random seed for reproducibility\n",
        "manualSeed = 999\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f4d94740a90>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cpu6caYTQs-3"
      },
      "source": [
        "dataset_path = \"/content/drive/MyDrive/CIS 581 Final Project/Project/full_dataset.npy\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNeurL_zmjmh"
      },
      "source": [
        "def normalise(dataset):\n",
        "  central_pt_idx = 8\n",
        "\n",
        "  normalised_data = np.zeros(dataset.shape)\n",
        "  norm_data = np.zeros(dataset.shape)\n",
        "\n",
        "  for i in range(len(dataset)):\n",
        "    diff = dataset[i]-dataset[i][central_pt_idx]\n",
        "    norm_data[i] = dataset[i]/np.mean(np.linalg.norm(diff))\n",
        "    normalised_data[i] = norm_data[i]-norm_data[i][central_pt_idx]\n",
        "\n",
        "  return torch.FloatTensor(normalised_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqGrdqUlnZzY",
        "outputId": "dff776c9-4a7d-4bdc-d4ee-532a1111bbcc"
      },
      "source": [
        "n_joints = 15 \n",
        "\n",
        "dataset = np.load(dataset_path)[:,:15,:]\n",
        "dataset = normalise(dataset)\n",
        "print (dataset.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([52647, 15, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3D7rQaVg2DZ"
      },
      "source": [
        "train_size = 3000\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, validation_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i_b3c74naAF"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O442I1KSeT3Z"
      },
      "source": [
        "batch_size = 64\n",
        "workers = 2\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=workers)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJ2BN64qURiX"
      },
      "source": [
        "class MLP_Generator(nn.Module):\n",
        "  def __init__(self, input_size, output_size):\n",
        "    super().__init__()  # needed to invoke the properties of the parent class nn.Module\n",
        "    hiddensize = 1024\n",
        "    self.layer1 = nn.Linear(input_size, hiddensize)\n",
        "    self.layer2 = nn.Linear(hiddensize, hiddensize)\n",
        "    self.layer3 = nn.Linear(hiddensize, hiddensize)\n",
        "    self.out_layer = nn.Linear(hiddensize, output_size)\n",
        "    self.leaky_relu = nn.LeakyReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x1 = self.layer1(x)\n",
        "    x1 = self.leaky_relu(x1)\n",
        "\n",
        "    x2 = self.layer2(x1)\n",
        "    x2 = self.leaky_relu(x2)\n",
        "\n",
        "    x2 = self.layer3(x2)\n",
        "    x3 = self.leaky_relu(x2+x1)\n",
        "    x3 = self.out_layer(x3)\n",
        "    return x3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFDpHt48VLBO"
      },
      "source": [
        "class MLP_Discriminator(nn.Module):\n",
        "  def __init__(self, input_size, output_size):\n",
        "    super().__init__()  # needed to invoke the properties of the parent class nn.Module\n",
        "    hiddensize = 1024\n",
        "    self.layer1 = nn.Linear(input_size, hiddensize)\n",
        "    self.layer2 = nn.Linear(hiddensize, hiddensize)\n",
        "    self.layer3 = nn.Linear(hiddensize, hiddensize)\n",
        "    self.out_layer = nn.Linear(hiddensize, output_size)\n",
        "    self.leaky_relu = nn.LeakyReLU()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x1 = self.layer1(x)\n",
        "    x1 = self.leaky_relu(x1)\n",
        "\n",
        "    x2 = self.layer2(x1)\n",
        "    x2 = self.leaky_relu(x2)\n",
        "\n",
        "    x2 = self.layer3(x2)\n",
        "    x3 = self.leaky_relu(x2+x1)\n",
        "    x3 = self.out_layer(x3)\n",
        "    # convert to binary preds 0-1 for BCE Loss\n",
        "    x3 = self.sigmoid(x3)\n",
        "    return x3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqjvFEisV_EV"
      },
      "source": [
        "def rotate_project(realpose2d, z_predicted_gen):\n",
        "  # return projected 2D pose from the genertaor's 3D pose after a random theta rotation\n",
        "  n_joints =  z_predicted_gen.shape[1]\n",
        "  batchsize = z_predicted_gen.shape[0]\n",
        "  x = realpose2d[:, 0:n_joints]\n",
        "  y = realpose2d[:, n_joints:]\n",
        "\n",
        "  theta = np.random.default_rng().uniform(0, 2 * np.pi, batchsize).reshape(-1, 1)\n",
        "  cos_theta = torch.FloatTensor(np.cos(theta)).to(device)\n",
        "  sin_theta = torch.FloatTensor(np.sin(theta)).to(device)\n",
        "\n",
        "  x_new = x * cos_theta + z_predicted_gen * sin_theta\n",
        "  y_new = y\n",
        "\n",
        "  fake2dpose = torch.cat((x_new, y_new), axis=1)\n",
        "\n",
        "  return fake2dpose\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT-CQPNidKLh"
      },
      "source": [
        "def L_angle(z, xy):\n",
        "  # Additional loss component to avoid inverted 3D poses\n",
        "  #neck->nose\n",
        "  f_z = z[:,1] - z[:,0]\n",
        "  f_x = xy[:,1] - xy[:,0]\n",
        "  f_n = torch.sqrt(f_z**2 + f_x**2)\n",
        "\n",
        "  #right shoulder->left shoulder\n",
        "  s_z = z[:,2] - z[:,5]\n",
        "  s_x = xy[:,2] - xy[:,5]\n",
        "  s_n = torch.sqrt(s_z**2 + s_x**2)\n",
        "\n",
        "  sin_beta = (f_z*s_x - f_x*s_z) / (f_n*s_n)\n",
        "  l_angle = F.relu(-sin_beta)\n",
        "\n",
        "  return torch.mean(l_angle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtbcorqOEUPX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1381f6bb-0c8b-41b1-aa03-dd47deef5431"
      },
      "source": [
        "train = False   # Make train true if you need to rerun training\n",
        "gen_model = []\n",
        "desc_model = []\n",
        "\n",
        "gen_model_path = \"/content/drive/MyDrive/CIS 581 Final Project/Project/Full MPII Dataset/Gen_model_\"\n",
        "desc_model_path = \"/content/drive/MyDrive/CIS 581 Final Project/Project/Full MPII Dataset/Discr_model_\"\n",
        "\n",
        "if not train:  # Make train false to load pre-trained models\n",
        "  gen_model = torch.load(gen_model_path, map_location=device)\n",
        "  desc_model = torch.load(desc_model_path, map_location=device)\n",
        "\n",
        "  print (gen_model, desc_model)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP_Generator(\n",
            "  (layer1): Linear(in_features=30, out_features=1024, bias=True)\n",
            "  (layer2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (layer3): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (out_layer): Linear(in_features=1024, out_features=15, bias=True)\n",
            "  (leaky_relu): LeakyReLU(negative_slope=0.01)\n",
            ") MLP_Discriminator(\n",
            "  (layer1): Linear(in_features=30, out_features=1024, bias=True)\n",
            "  (layer2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (layer3): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (out_layer): Linear(in_features=1024, out_features=1, bias=True)\n",
            "  (leaky_relu): LeakyReLU(negative_slope=0.01)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSy0niX3WP-o"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "if train:     ### Make train true if you need to rerun training\n",
        "  epochs = 30\n",
        "  vis_const = 100\n",
        "  input_size = n_joints*2 # x and y flattened\n",
        "  gen_model = MLP_Generator(input_size, n_joints).to(device)\n",
        "  desc_model = MLP_Discriminator(input_size, 1).to(device)\n",
        "\n",
        "  criterion = nn.BCELoss()\n",
        "  gen_optimizer = optim.Adam(gen_model.parameters(), lr=5e-5) \n",
        "  desc_optimizer = optim.Adam(desc_model.parameters(), lr=1e-5)\n",
        "\n",
        "  train_running_loss_desc = []\n",
        "  train_running_loss_gen = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      running_loss_desc = 0\n",
        "      running_loss_gen = 0\n",
        "      for i, pose in enumerate(train_dataloader, 0):\n",
        "          pose2d = pose.view(-1, input_size).to(device)\n",
        "\n",
        "          ## Descriminator ##\n",
        "          # zero gradient\n",
        "          desc_optimizer.zero_grad()\n",
        "\n",
        "          # get fake preds from generator and adapt them\n",
        "          z_predicted_gen = gen_model(pose2d)\n",
        "          fake2dposes = rotate_project(pose2d, z_predicted_gen)\n",
        "\n",
        "          # descrimintor input: append real pose2d and fake2dposes with correct labels \n",
        "          all_labels = torch.zeros(pose2d.shape[0]*2, 1).to(device)\n",
        "          all_labels[0:pose2d.shape[0]] = 1\n",
        "          input_to_desc = torch.cat((pose2d, fake2dposes), dim=0).to(device)\n",
        "\n",
        "          # Get discriminator predictions and backprop\n",
        "          y_predicted_desc = desc_model(input_to_desc)\n",
        "          loss_desc = criterion(y_predicted_desc, all_labels)\n",
        "          running_loss_desc += loss_desc.item()\n",
        "          loss_desc.backward()\n",
        "          desc_optimizer.step()\n",
        "\n",
        "          ## Generator ##\n",
        "          #Take multiple generator steps for each descriminator step\n",
        "          gen_loss_steps = []\n",
        "          gen_steps = 70\n",
        "          for k in range(0, gen_steps):\n",
        "            # zero gradient\n",
        "            gen_optimizer.zero_grad()\n",
        "\n",
        "            # again get fake preds from generator and adapt them\n",
        "            z_predicted_gen = gen_model(pose2d)\n",
        "            fake2dposes = rotate_project(pose2d, z_predicted_gen)\n",
        "\n",
        "            # Get discriminator predictions on the fake poses and try to get them predicted as real (so labels=1)\n",
        "            y_predicted_desc = desc_model(fake2dposes)\n",
        "            labels =  torch.ones(pose2d.shape[0], 1).to(device)\n",
        "\n",
        "            loss_gen = criterion(y_predicted_desc, labels) + L_angle(z_predicted_gen, pose2d).to(device) \n",
        "            gen_loss_steps.append(loss_gen.item())\n",
        "            loss_gen.backward()\n",
        "            gen_optimizer.step()\n",
        "          \n",
        "          running_loss_gen+= np.average(gen_loss_steps)\n",
        "          \n",
        "\n",
        "      train_running_loss_desc.append(running_loss_desc)\n",
        "      train_running_loss_gen.append(running_loss_gen)\n",
        "\n",
        "      if (epoch+1) % 3 == 0:\n",
        "          print(f'epoch: {epoch+1}, desc_loss: {running_loss_desc:.4f}, gen_loss: {running_loss_gen:.4f}, overall_loss: {running_loss_desc+running_loss_gen:.4f}')\n",
        "  \n",
        "  \n",
        "  torch.save(gen_model, gen_model_path+str(datetime.datetime.now()))\n",
        "  torch.save(desc_model, desc_model_path+str(datetime.datetime.now()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUUsAm1thVkS"
      },
      "source": [
        "def visualise2dpose(x, y):\n",
        "  fig = plt.figure()\n",
        "  plt.scatter(x, y)\n",
        "  for i in range(0, n_joints):\n",
        "    plt.annotate(i, (x[i], y[i]))\n",
        "\n",
        "  plt.plot(x[0:2], y[0:2], 'go-')\n",
        "  plt.plot(x[1:3], y[1:3], 'ro-')\n",
        "  plt.plot(x[2:4], y[2:4], 'ro-')\n",
        "  plt.plot(x[3:5], y[3:5], 'ro-')\n",
        "\n",
        "  plt.plot(x[5:7], y[5:7], 'ro-')\n",
        "  plt.plot(x[6:8], y[6:8], 'ro-')\n",
        "\n",
        "  plt.plot([x[1],x[5]],[y[1],y[5]],'ro-')\n",
        "  plt.plot([x[1],x[8]],[y[1],y[8]],'go-')\n",
        "\n",
        "  plt.plot([x[8],x[9]],[y[8],y[9]],'k-')\n",
        "  plt.plot([x[8],x[12]],[y[8],y[12]],'k-')\n",
        "  plt.plot([x[9],x[10]],[y[9],y[10]],'k-')\n",
        "  plt.plot([x[12],x[13]],[y[12],y[13]],'k-')\n",
        "\n",
        "  plt.plot([x[10],x[11]],[y[10],y[11]],'k-')\n",
        "  plt.plot([x[13],x[14]],[y[13],y[14]],'k-')\n",
        "\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Eba_rVlicKQ"
      },
      "source": [
        "def visualise3dpose(x, y, z):\n",
        "  fig = plt.figure()\n",
        "  ax = plt.axes(projection='3d')\n",
        "  ax.scatter3D(x, y, z)\n",
        "  for i in range(0, n_joints):\n",
        "    ax.text3D(x[i], y[i], z[i], i)\n",
        "\n",
        "  plt.plot(x[0:2], y[0:2], z[0:2], 'go-')\n",
        "  plt.plot(x[1:3], y[1:3], z[1:3], 'ro-')\n",
        "  plt.plot(x[2:4], y[2:4], z[2:4], 'ro-')\n",
        "  plt.plot(x[3:5], y[3:5], z[3:5], 'ro-')\n",
        "\n",
        "  plt.plot(x[5:7], y[5:7], z[5:7], 'ro-')\n",
        "  plt.plot(x[6:8], y[6:8], z[6:8], 'ro-')\n",
        "\n",
        "  plt.plot([x[1],x[5]],[y[1],y[5]], [z[1],z[5]], 'ro-')\n",
        "  plt.plot([x[1],x[8]],[y[1],y[8]], [z[1],z[8]], 'go-')\n",
        "\n",
        "  plt.plot([x[8],x[9]],[y[8],y[9]], [z[8],z[9]],'k-')\n",
        "  plt.plot([x[8],x[12]],[y[8],y[12]],[z[8],z[12]],'k-')\n",
        "  plt.plot([x[9],x[10]],[y[9],y[10]],[z[9],z[10]],'k-')\n",
        "  plt.plot([x[12],x[13]],[y[12],y[13]],[z[12],z[13]],'k-')\n",
        "\n",
        "  plt.plot([x[10],x[11]],[y[10],y[11]],[z[10],z[11]],'k-')\n",
        "  plt.plot([x[13],x[14]],[y[13],y[14]],[z[13],z[14]],'k-')\n",
        "  \n",
        "  ax.set_xlim3d(min(x), max(x), 0.05)\n",
        "  ax.set_ylim3d(min(y), max(y), 0.05)\n",
        "  ax.set_zlim3d(min(z), max(z), 0.05)\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMDPRlkN5T-y"
      },
      "source": [
        "def visualise3dpose_plotly(x, y, z, img_num):\n",
        "  n_joints = 15\n",
        "  i = list(np.arange(0,n_joints))\n",
        "  \n",
        "  fig = go.Figure(data=[go.Scatter3d(x=x[:n_joints], y=y[:n_joints], z=z[:n_joints], text= i, \n",
        "                                   mode='markers')])\n",
        "  \n",
        "\n",
        "  \n",
        "  figb = go.Figure(data=[go.Scatter3d(x=[x[0]], y=[y[0]], z=[z[0]], text= 0,\n",
        "                                   mode='markers', \n",
        "                                   marker=dict(color='#E3BC9A',size=26))])\n",
        "\n",
        "  fig2 = px.line_3d(x = x[0:2], y = y[0:2], z = z[0:2])\n",
        "  fig2.update_traces(line=dict(color = '#FF0080', width = 13))\n",
        "  fig3 = px.line_3d(x= x[1:3], y = y[1:3], z = z[1:3])\n",
        "  fig3.update_traces(line=dict(color = '#FD7F20', width =13))\n",
        "  fig4 = px.line_3d(x = x[2:4], y= y[2:4], z = z[2:4])\n",
        "  fig4.update_traces(line=dict(color = '#FDB750', width =13))\n",
        "  fig5 = px.line_3d(x = x[3:5], y = y[3:5], z =z[3:5])\n",
        "  fig5.update_traces(line=dict(color = '#ECF87F', width =13))\n",
        "  fig6 = px.line_3d(x = x[5:7], y = y[5:7], z = z[5:7])\n",
        "  fig6.update_traces(line=dict(color = '#2C5E1A', width =13))\n",
        "  fig7 = px.line_3d(x = x[6:8], y = y[6:8], z = z[6:8])\n",
        "  fig7.update_traces(line=dict(color = '#1A4314', width=13 ))\n",
        "  fig8 = px.line_3d( x =[x[1],x[5]],y =[y[1],y[5]], z = [z[1],z[5]])\n",
        "  fig8.update_traces(line=dict(color = '#32CD32', width =13))\n",
        "  fig9 = px.line_3d( x =[x[1],x[8]],y = [y[1],y[8]], z =  [z[1],z[8]])\n",
        "  fig9.update_traces(line=dict(color = '#ff0000', width = 25))\n",
        "  fig10 = px.line_3d( x =[x[8],x[9]],y = [y[8],y[9]], z = [z[8],z[9]])\n",
        "  fig10.update_traces(line=dict(color = '#00c579', width =15))\n",
        "  fig11 = px.line_3d( x =[x[8],x[12]],y = [y[8],y[12]], z = [z[8],z[12]])\n",
        "  fig11.update_traces(line=dict(color = '#00ffff', width = 15))\n",
        "  fig12 = px.line_3d( x =[x[9],x[10]], y =  [y[9],y[10]], z = [z[9],z[10]])\n",
        "  fig12.update_traces(line=dict(color = '#009e61', width =15))\n",
        "  fig17 = px.line_3d( x = [x[10],x[11]], y = [y[10],y[11]], z = [z[10],z[11]])\n",
        "  fig17.update_traces(line=dict(color = '#2db4af', width =15))\n",
        "  fig13 = px.line_3d( x =[x[12],x[13]],y = [y[12],y[13]], z = [z[12],z[13]])\n",
        "  fig13.update_traces(line=dict(color = '#216bd6', width = 15))\n",
        "  fig14 = px.line_3d( x =[x[13],x[14]], y= [y[13],y[14]], z = [z[13],z[14]])\n",
        "  fig14.update_traces(line=dict(color = '#1a56ab', width = 15))\n",
        "\n",
        "\n",
        "  figa = go.Figure(data=fig.data + figb.data + fig2.data + fig3.data + fig4.data +fig5.data +fig6.data + fig7.data +fig8.data +\n",
        "                   fig9.data + fig10.data + fig11.data +fig12.data + fig13.data + fig14.data \n",
        "                   + fig17.data )\n",
        "\n",
        "\n",
        "  figa.update_layout( scene=dict(annotations = [                                             \n",
        "                                                 dict(showarrow=True, x = x[0],y = y[0], z=z[0], text = 0),\n",
        "                                                 dict(showarrow=True, x = x[1],y = y[1], z=z[1], text = 1), \n",
        "                                                 dict(showarrow=True, x = x[2],y = y[2], z=z[2], text = 2),\n",
        "                                                 dict(showarrow=True, x = x[3],y = y[3], z=z[3], text = 3),\n",
        "                                                 dict(showarrow=True, x = x[4],y = y[4], z=z[4], text = 4),\n",
        "                                                 dict(showarrow=True, x = x[5],y = y[5], z=z[5], text = 5),\n",
        "                                                 dict(showarrow=True, x = x[6],y = y[6], z=z[6], text = 6),\n",
        "                                                 dict(showarrow=True, x = x[7],y = y[7], z=z[7], text = 7),\n",
        "                                                 dict(showarrow=True, x = x[8],y = y[8], z=z[8], text = 8),\n",
        "                                                 dict(showarrow=True, x = x[9],y = y[9], z=z[9], text = 9),\n",
        "                                                 dict(showarrow=True, x = x[10],y = y[10], z=z[10], text = 10),\n",
        "                                                 dict(showarrow=True, x = x[11],y = y[11], z=z[11], text = 11),\n",
        "                                                 dict(showarrow=True, x = x[12],y = y[12], z=z[12], text = 12),\n",
        "                                                 dict(showarrow=True, x = x[13],y = y[13], z=z[13], text = 13),\n",
        "                                                 dict(showarrow=True, x = x[14],y = y[14], z=z[14], text = 14)]\n",
        "                                                   ,xaxis = dict(nticks = int((max(x)-min(x))/0.01), range =[min(x),max(x)]), \n",
        "                                                    yaxis = dict(nticks = int((max(y)-min(y))/0.01), range =[min(y),max(y)]),\n",
        "                                                    zaxis = dict(nticks = int((max(z)-min(z))/0.01), range =[min(z),max(z)])\n",
        "                                                 ))\n",
        "  figa.show()\n",
        "\n",
        "  # Save 3D Plots\n",
        "  path = \"/content/drive/MyDrive/CIS 581 Final Project/Project/3DPlot_Results/\"+ str(img_num) +\".html\"\n",
        "  figa.write_html(path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAlRG_7MMQ9j"
      },
      "source": [
        "dataset = np.load(\"/content/drive/MyDrive/CIS 581 Final Project/Project/test_dataset.npy\")\n",
        "images = np.load(\"/content/drive/MyDrive/CIS 581 Final Project/Project/test_dataset2.npy\")\n",
        "image_path = \"/content/drive/MyDrive/CIS 581 Final Project/Project/MPII Dataset/\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywfOuyfcRTrZ"
      },
      "source": [
        "import matplotlib.image as mpimg\n",
        "for i in range(0, len(images)):\n",
        "  print(i)\n",
        "  img = mpimg.imread(image_path+images[i])\n",
        "  img_name = images[i]\n",
        "  img2 = np.fliplr(img)\n",
        "  plt.imshow(img2, origin='upper')\n",
        "  dataset = normalise(dataset)\n",
        "\n",
        "  x, y = -dataset[i, :n_joints, 0], -dataset[i, :n_joints, 1]\n",
        "  visualise2dpose(x, y)\n",
        "\n",
        "  x, y = -dataset[i, :n_joints, 0].cpu().detach().numpy(), -dataset[i, :n_joints, 1].cpu().detach().numpy()\n",
        "\n",
        "  pose2d = torch.FloatTensor(np.vstack((x, y)).T).reshape(1, -1).to(device)\n",
        "  z = gen_model(pose2d).cpu().detach().numpy()[0]\n",
        "\n",
        "  imgnum = str(img_name)+\"_img\"+str(i)\n",
        "  visualise3dpose_plotly(z,x,y,imgnum )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}